{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in wet files to spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract the url the article, map in to url->text pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def censor(text):\n",
    "    censoredText = \"\"\n",
    "    URI = \"\"\n",
    "    for line in text.split('\\n'):\n",
    "        if line.startswith(\"WARC-Target-URI:\"):\n",
    "            URI = line[17:]\n",
    "        elif line.startswith(\"WARC\") or line.startswith(\"Content-\"):\n",
    "            continue\n",
    "        else:\n",
    "            censoredText += line\n",
    "    return (URI,censoredText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete non-text pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_text(markedtext):\n",
    "    if markedtext[0]:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sepertate textfile by WARC/1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType\n",
    "schema = StructType([\n",
    "    StructField(\"URI\", StringType(), True), StructField(\"text\", StringType(), False)\n",
    "])\n",
    "\n",
    "def load_article(category_name):\n",
    "    text_file = sc.newAPIHadoopFile(\"small.wet\", \"org.apache.hadoop.mapreduce.lib.input.TextInputFormat\",\n",
    "            \"org.apache.hadoop.io.LongWritable\", \"org.apache.hadoop.io.Text\",\n",
    "            conf={\"textinputformat.record.delimiter\": \"WARC/1.0\"}).map(lambda l:l[1])\n",
    "    return text_file.map(censor).filter(is_text).toDF(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "micro_articles = load_article(\"small.wet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 URI|                text|\n",
      "+--------------------+--------------------+\n",
      "|http://01marocain...|01marocainLe site...|\n",
      "|http://10.asiae.c...|�ƽþư��� �ƽþư��� �...|\n",
      "|http://10000birds...|10,000 Birds | Wh...|\n",
      "|http://1012lounge...|10/12 LoungeHomeE...|\n",
      "|http://1015store....|DRESSES BY COLORS...|\n",
      "|http://1019amprad...|Happy Holidays « ...|\n",
      "|http://102therive...|Get Important New...|\n",
      "|http://1035kissfm...|'Reading Rainbow'...|\n",
      "|http://1037theq.i...|Tiesto celebrates...|\n",
      "|http://1065ctq.ih...|New Electronic Li...|\n",
      "|http://10kbullets...|Neon Nights – 10,...|\n",
      "|http://12160.info...|Both Republicans ...|\n",
      "|http://12under12u...|12under12under201...|\n",
      "|http://1350kman.c...|Settlement Reache...|\n",
      "|http://14ers.com/...|14ers.com • Login...|\n",
      "|http://16sarkisoz...|Şarkı sözü: Nasip...|\n",
      "|http://17hmr.net/...|An Error Has Occu...|\n",
      "|http://17hmr.net/...|LoginWelcome, Gue...|\n",
      "|http://17hmr.net/...|An Error Has Occu...|\n",
      "|http://17hmr.net/...|An Error Has Occu...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "micro_articles.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:spark]",
   "language": "python",
   "name": "conda-env-spark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
